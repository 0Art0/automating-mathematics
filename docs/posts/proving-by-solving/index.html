<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.82.0" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Knot so easy: Mathematical Proofs from High-performance Solvers? &middot; Artificial Intelligence and Mathematics</title>
  <meta name="description" content="" />

  
  <link type="text/css" rel="stylesheet" href="https://siddhartha-gadgil.github.io/automating-mathematics/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://siddhartha-gadgil.github.io/automating-mathematics/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://siddhartha-gadgil.github.io/automating-mathematics/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://siddhartha-gadgil.github.io/automating-mathematics/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://siddhartha-gadgil.github.io/automating-mathematics/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="https://siddhartha-gadgil.github.io/automating-mathematics/favicon.png">

  
  <link rel="icon" href="https://siddhartha-gadgil.github.io/automating-mathematics/IIScLogo.jpg">
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      displayMath: [ ['$$', '$$']],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea']
    },
    TeX: {
      Macros: {
        R: '\\mathbb{R}',
        Z: '\\mathbb{Z}',
        C: '\\mathbb{C}'
      }
    },
    messageStyle: "none",
    "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
    </script>
    <style>
      code {
      font-size: inherit;
      background-color: inherit !important;
      color: inherit !important;
      margin: inherit !important;
      padding: inherit !important;
    }
    </style>
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://siddhartha-gadgil.github.io/automating-mathematics/"><h1>Artificial Intelligence and Mathematics</h1></a>
      <p class="lead">
       Some thoughts and experiments towards automating mathematics. 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://siddhartha-gadgil.github.io/automating-mathematics/">Home</a> </li>
        <li><a href="https://github.com/siddhartha-gadgil/ProvingGround/"> ProvingGround </a></li><li><a href="http://math.iisc.ac.in/~gadgil"> Siddhartha Gadgil </a></li>
      </ul>
    </nav>

    <p>&copy; 2021. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>Knot so easy: Mathematical Proofs from High-performance Solvers?</h1>
  <time datetime=2021-04-14T12:24:23&#43;0530 class="post-date">Wed, Apr 14, 2021</time>
  <p>Computers are able to solve an increasing range of problems, many of which were believed not long ago to require human intelligence. Yet
there are fundamental limitations to what problems can be solved algorithmically, some known and other conjectured. By results of Gödel, Turing, Church and others we know, for instance, there is no computer program that given a mathematical statement as input, either gives a proof or (correctly) says that the statement is false.</p>
<p>Indeed, we cannot algorithmically solve even a seemingly simple class of problems: deciding whether a so called <a href="https://en.wikipedia.org/wiki/Diophantine_equation">Diophantine Equation</a>, has a solution. A Diophantine equation is a polynomial equation with integer coefficients, such as <code>$3n^2 + 7m^2 = r^3$</code>, with solutions being <em>integers</em> corresponding to the variables ($n$, $m$ and $r$ in the example) which satisfy the equation. For instance the Diophantine equation <code>$n^2 = 2$</code> has no solution even though as an equation over real numbers it has the solution <code>$n= \sqrt{2}$</code>. As a result of combined work of Martin Davis, Yuri Matiyasevich, Hilary Putnam and Julia Robinson during the 1950s and 1960s, there is no algorithm (i.e., computer program) to which we can input the coefficients of a Diophantine equation and which will tell us (correctly) whether the equation has integral solutions.</p>
<p>Yet, the above results should not be over-interpreted to say that proofs cannot be found by programs. Indeed if we turn from numbers to the other classical source of mathematics – Euclidean geometry, the situation is different. In the 1950s, Tarski proved that whether polynomial equations (and inequations) have solutions that are real numbers <strong>is</strong> decidable. Using coordinate geometry, statements in Euclidean geometry can be translated to such problems, and so are algorithmically decidable. Tarski&rsquo;s algorithm has been greatly improved, and algorithms of a more algebraic nature have also been developed, improved and implemented. Yet they remain slow.</p>
<p>This post is about by my experiments to use (as an amateur) state-of-the-art solvers to try in practice to prove such results and other related stuff. I started these experiments prompted by a lecture to undergraduate students, during which I used <strong>Z3</strong>, a high-performance solver from Microsoft, to solve a Sudoku problem (a standard demo for this technology), which was duly solved instantly. You can see such a demo <a href="https://rise4fun.com/Z3/Cs7p">online</a>, but the online version is slow. I looked around for examples of geometric theorems proved using <strong>Z3</strong> or its friends, but found none. So I decided to try my hands at proving this. Some years ago I had experimented with using <strong>Z3</strong> for an for recognizing <em>knotting</em>, which follows essentially immediately from a result of Kronheimer-Morwka, and I redid similar experiments.</p>
<p>Unfortunately, at least in the way I used them neither <strong>Z3</strong> nor <strong>CVC4</strong> (another similar system, and the champion in the latest competition) failed to prove the geometric result I sought. Yet, especially as these systems are vastly improving, it seems worthwhile to write about how such systems can be used at least in principle, especially since this does not seem to be widely known.</p>
<h2 id="p-versus-np-and-satsmt-solvers">P versus NP and SAT/SMT solvers</h2>
<p>Some problems, such as solving a system of linear equations, are not difficult at least once one knows a method to solve them. The thumb rule used is that if we can solve a problem with the number of steps being at most a polynomial in the size of the problem (for instance, the total number of digits in the coefficients of equations), then we consider the problem to be easy enough. The class of these problems is called <strong>P</strong> (i.e., Polynomial time).</p>
<p>A more interesting class of problems is once for which we can <em>check</em> that a solution is correct reasonably easily, but it is not clear how to find a solution in an easy manner. This is typically the case with puzzles like Jigsaws and Sudoku — indeed the appeal of puzzles perhaps lies in this feature. Such problems are called <strong>NP</strong> problems (or problems in the class <strong>NP</strong>). While it appears that many such problems do not have easy (i.e., polynomial time) solutions, there is no proof of this. Whether every problem whose solution is easy to check has a solution that is easy to find is the <strong>P</strong> versus <strong>NP</strong> problem.</p>
<p>What makes this problem specially interesting and fruitful is the Cook-Levine theorem from the early 1970s. This says that if one specific problem in NP, called the <em>Boolean satisfiability problem</em> (called SAT) has a polynomial time solution, then <em>every</em> problem that is in <strong>NP</strong> can be solved in polynomial time. It can be deduced that there are many other problems with the same property. Such problems are called <strong>NP</strong>-complete.</p>
<p>While the theoretical <strong>P</strong> vs <strong>NP</strong> problem remains mysterious, the Cook-Levine theorem has had some remarkable practical uses. Since so many classes of problems can be reduced to solving one class of problems, namely <strong>SAT</strong>, a powerful approach has been to develop various clever ways and powerful programs incorporating them, called <em>SAT solvers</em>, to solve <strong>SAT</strong> problems better, and then using these to solve other problems. An extension of SAT solvers are programs called SMT-solvers (for <em>Satisfiability Modulo Theories</em>).</p>
<p>The Boolean satisfiability problem (SAT), like the solvability of Diophantine equations, asks whether a set of equations has a solution (sets of equations having solutions are said to be <em>satisfiable</em>). However these are equations with variables representing not integers or reals but so called <em>Booleans</em>, i.e., which can be either <code>true</code> or <code>false</code>. From such variables we build statements using the logical operations <em>and</em>, <em>or</em> and <em>not</em>. For example, for Boolean variables <code>P</code> and <code>Q</code> we may require than <code>P</code> is <code>true</code> and <code>Q</code> is false (i.e., <code>not Q</code> is true). Given a finite list of such conditions, we may or may not have a solution — for example <code>P</code> being true and <code>P</code> being false cannot both be satisfied. Determining whether there is a solution is the problem SAT. Clearly given a solution it is easy to check that it is correct, so SAT is in <strong>NP</strong>.</p>
<p>While it appears that no program can solve all SAT problems reasonably fast (i.e., in polynomial time), high-performance SAT solvers try to solve SAT problems as quickly as possible in practice. Indeed in many cases SAT problems are not that hard — for example if there are either so many solutions that one can readily find one or so many constraints that one can readily show that there are none.</p>
<p>SMT solvers extend these ideas to handle problems that involve not just Booleans, but also integers and real numbers. Thus, we can require that a collection of equations are satisfied, or a mixture of equations and inequations (such as <code>$x^2 &lt; 3$</code>, <code>$y^2 + z^2 \neq 1$</code>) or even a logical combination of these (e.g. <code>($x^2 &lt; 3)\vee(y^2 + z^2 \neq 1)$</code>, where <code>$\vee$</code> is the logical <em>or</em>). Again many instances of these problems are hard, and now include even ones with no algorithmic solution. Nevertheless the approach taken is to solve as large a class of problems as efficiently as possible.</p>
<h2 id="pappus-hexagon-theorem-attempting-geometry">Pappus hexagon theorem: attempting geometry</h2>
<p>In principle SMT solvers can be used to solve problems in Euclidean geometry. I attempted to prove the <em>Pappus hexagon theorem</em>, which I next describe. In addition to being a typical geometry result, this has a deeper mathematical meaning (corresponding to commutativity for affine geometries over division rings).</p>
<p>Suppose we are given two lines, with points $a$, $b$ and $c$ on the first line and $A$, $B$ and $C$ on the second line as in the figure below. We consider the general case, where no pair of lines involving these points are parallel. Let $P$ be the intersection of the lines $Ab$ and $aB$, $Q$ the intersection of $Ac$ and $aC$, and $R$ the intersection of $Bc$ and $bC$. The Pappus hexagon theorem is the result that $P$, $Q$ and $R$ are <em>collinear</em>, i.e., there is a line containing all three of these points.</p>
<p><img src="https://siddhartha-gadgil.github.io/automating-mathematics/Pappus.png" alt="Pappus Theorem"></p>
<h3 id="equations-for-collinearity">Equations for collinearity</h3>
<p>We shall translate this into a problem of deciding whether a collection of polynomial equation and inequations over reals has a solution, which as Tarski showed is decidable. First, we recall that collinearity can be expressed as a polynomial equality. Namely,
points with coordinates <code>$(x_1, y_1)$</code>, <code>$(x_2, y_2)$</code> and <code>$(x_3, y_3)$</code>, which we assume to be distinct, are collinear if and only if
<code>$$\frac{y_2 - y_1}{x_2 - x_1} = \frac{y_3 - y_1}{x_3 - x_1}$$</code>
which is equivalent to <code>$$(y_2 - y_1)(x_3 - x_1) = (y_3 - y_1)(x_2 - x_1).$$</code></p>
<h3 id="a-simple-problem">A simple problem</h3>
<p>As a warmup and sanity check, I set up the problem of showing that for an arbitrary point $P = (x, y)$, the three points $P=(x, y)$, $O=(0, 0)$ and $-P=(-x, -y)$ are collinear.</p>
<p>We prove such results using SAT/SMT solvers by contradiction. In this case, for variables $x$ and $y$, we impose the condition that the points $P$, $O$ and $-P$ are <em>not</em> collinear. If the solver shows that this cannot be satisfied, then it follows that the points are always collinear. Observe that the condition of not being collinear just means that equation in the above equation is replaced by the inequation <code>$(y_2 - y_1)(x_3 - x_1) \neq (y_3 - y_1)(x_2 - x_1)$</code>.</p>
<p>Indeed the solvers <strong>Z3</strong> and <strong>cvc4</strong> prove this result instantly — more precisely, <strong>Z3</strong> took $0.012$ seconds and <strong>CVC4</strong> took $0.094$ seconds.</p>
<h3 id="choosing-coordinates">Choosing coordinates</h3>
<p>While one can (and I initially did) take arbitrary coordinates for the $6$ points $a$, $b$, $c$, $A$, $B$ and $C$ and add equations for their being collinear, we consider a simpler variant where we choose coordinates and parametrize the points. Namely, we can take $a$, $b$ and $c$ on the x-axis with $a = (1, 0)$. Then we have $b = (1 + u, 0)$ and $c = (1 + u + v, 0)$ with $u&gt;0$ and $v&gt;0$. Similarly, if we let <code>$A = (x_A, y_A)$</code>, then we can assume that <code>$B = (x_A(1+ U), y_A(1 + U))$</code> for some $U &gt; 0$ and <code>$C = (x_A(1+ U + V), y_A(1 + U + V))$</code> for some $V &gt; 0$. Further, we can assume that $y_A &gt; 0$.</p>
<p>We take the points <code>$P= (x_P, y_p)$</code>, <code>$Q = (x_Q, y_Q)$</code> and <code>$R= (x_R, y_R)$</code> to have arbitrary coordinates. We then add equations corresponding to their being intersection points as we see below. Thus, we have $12$ variables in all, $6$ of them the parameters $u$, $v$, $x_A$, $y_A$, $U$ and $V$ for the problem and $6$ more coordinates of the intersection points. Further, we have inequalities $u &gt;0$, $v &gt;0$, <code>$y_A &gt;0$</code>, $U &gt; 0$ and $V &gt;0$.</p>
<h3 id="formulating-using-polynomial-equations-and-inequations">Formulating using polynomial equations and inequations</h3>
<p>We reformulate the Pappus hexagon theorem in terms of collinearity. Observe that $P$ being the intersection point of $Ab$ and $aC$ is equivalent to both the triples of points $(A, P, b)$ and $(a, P, B)$ being collinear. We have similar conditions for $Q$ and $R$. Thus, the hypothesis can be formulated in terms of collinearity (and distinctness) of various triples of points.</p>
<p>Finally, the conclusion is that $P$, $Q$ and $R$ are collinear. We seek to prove this by contradiction, namely we add the condition that they are not collinear, and show that the resulting system cannot be satisfied. Again, the condition that the points are not collinear gives an inequation.</p>
<p>In summary, we have a problem asking whether a set of algebraic equations and inequations has a solution over reals. This system has <code>$12$</code> variables, with <code>$6$</code> equations corresponding to collinearity, <code>$5$</code> inequations stating that variables are positive and an inequation (to contradict) stating that three points are not collinear.</p>
<h3 id="running-smt-solvers">Running SMT solvers</h3>
<p>As mentioned in the introduction, neither of the SMT solvers was able to prove the Pappus hexagon theorem. This is in spite of my (undoubtedly amateur) attempts at changing their parameters to raise various limits.</p>
<p>To try to assess how far they were from proving the theorem, I attempted a simpler variant. Instead of having all six of $u$, $v$, $x_A$, $y_A$, $U$ and $V$ as variables (so proving the result for all values of these), I added additional equations fixing some of them. Since all but $x_A$ were known to be positive, for convenience conditions could only be added by choosing random positive numbers corresponding to some of the five variables $u$, $v$, $y_A$, $U$ and $V$ and adding corresponding equations — for example, the program could pick <code>$c &gt; 0$</code> at random and add the equation <code>u = c</code>.</p>
<p>When all $5$ of the variables were fixed (leaving only $x_A$ to vary), <strong>Z3</strong> solved the problem instantly. When $4$ of the $5$ were fixed, the theorem was proved in about 6 seconds. However, when only $3$ were fixed I could not get either solver to prover the result, in spite of changing parameters.</p>
<h2 id="knot-so-easy">Knot so easy</h2>
<p>A basic decision problem in topology is the <em>unknotting problem</em>, which is deciding whether a smooth embedding $K$ of the circle into <code>$\R^3$</code> is the boundary of a smooth embedding of a disc. We say $K$ is unknotted if it bounds a smoothly embedded disc. This was solved in the 1950s by Haken. However, Haken&rsquo;s algorithm was doubly exponential, and so not practical.</p>
<p>As had been independently observed by many people, there is another kind of algorithm that follows immediately from some deep work of Kronheimer-Mrowka where they proved what was called <em>Property P</em>, a baby version of the Poincaré conjecture (Perelman proved the Poincaré conjecture itself some years after this work of Kronheimer-Mrowka).</p>
<p>It has been known from the 1950s that the knotting problem is equivalent to whether the so called <em>Knot Group</em> <code>$G_K$</code> associated to a knot <code>$K$</code> is isomorphic to the integers. However deciding whether groups are isomorphic, or even whether a group is non-trivial, are algorithmically undecidable. What Kronheimer-Mrowka showed was that a certain quotient <code>$\bar{G}_K$</code> of <code>$G_K$</code> (the fundamental group of the manifold obtained by $+1$ surgery about the knot) is the trivial group if and only if $K$ is unknotted.</p>
<p>As mentioned above, this criterion does not give an algorithm as we cannot decide whether a group is trivial. However, Kronheimer-Mrowka proved more, namely if $K$ is not unknotted, then <code>$\bar{G}_K$</code> has a non-trivial homomorphism into <code>$SU(2)$</code>, the group of unit quaternions. Such representations are given in terms of algebraic equations, and inequations can be used to characterize non-triviality. Thus, unknotting is a special case of a problem solvable in principle — that of determining whether a group (given by a presentation) has a non-trivial homomorphism into unit quaternions.</p>
<p>I implemented the translation of the group theoretic problem to SMT problems, and attempted this for a few presentations of groups. Once more, my success was limited. For simple presentations I easily obtained either non-trivial homomorphisms or a proof of non-existence of these. However the solvers quickly reached their limits.</p>
<p>I must mention that now there is now a practical solution of the unknotting problem, again due to Kronheimer-Mrowka, based on a characterization in terms of <em>Khovanov homology</em>.</p>

</div>


    </main>

    
      
    
  </body>
</html>
